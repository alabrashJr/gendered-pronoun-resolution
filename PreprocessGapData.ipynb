{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/google-research-datasets/gap-coreference.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constants.py\t gap-development.tsv  gap-test.tsv\t  LICENSE\r\n",
      "CONTRIBUTING.md  gap_scorer.py\t      gap-validation.tsv  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!dir gap-coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'gap-coreference/gap-development.tsv'\n",
    "val_file = 'gap-coreference/gap-validation.tsv'\n",
    "test_file = 'gap-coreference/gap-test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset  A-coref                B  \\\n",
       "0             274     Cheryl Cassidy       191     True          Pauline   \n",
       "1             284          MacKenzie       228     True    Bernard Leach   \n",
       "2             265            Angeloz       173    False       De la Sota   \n",
       "3             321               Hell       174    False  Henry Rosenthal   \n",
       "4             437  Kitty Oppenheimer       219    False           Rivera   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0       207    False  http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1       251    False      http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2       246     True  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3       336     True          http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4       294     True        http://en.wikipedia.org/wiki/Jessica_Rivera  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_file,sep = '\\t')\n",
    "val_df = pd.read_csv(train_file,sep = '\\t')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data\n",
    "\n",
    "Note down token positions of P, A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import (Dataset,DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "\n",
    "from pytorch_transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_array(row):\n",
    "        p_offset = row['Pronoun-offset']\n",
    "        a_offset = row['A-offset']\n",
    "        b_offset = row['B-offset']\n",
    "        offsets = {'p':p_offset,'a':a_offset,'b':b_offset}\n",
    "        \n",
    "        keys = sorted(offsets,key=lambda z : offsets[z])\n",
    "        positions = sorted(offsets.values())\n",
    "        lengths = [positions[i] - positions[i-1] if i >0 else pos for i,pos in enumerate(positions)]\n",
    "        \n",
    "        text = row['Text']\n",
    "        positions.append(len(text))\n",
    "        \n",
    "        all_tokens = []\n",
    "        prev_pos = 0\n",
    "        for pos in positions:\n",
    "            subtext = text[prev_pos:pos]\n",
    "            prev_pos = pos\n",
    "            tokens = tokenizer.tokenize(subtext)\n",
    "            all_tokens.append(tokens)\n",
    "        \n",
    "        return all_tokens, keys\n",
    "\n",
    "\n",
    "\n",
    "def get_token_pos(all_tokens, keys):\n",
    "    token_positions = {}\n",
    "    prev = 0\n",
    "    for i,tokens in enumerate(all_tokens[:-1]):\n",
    "        position = prev+len(tokens)\n",
    "        prev = position\n",
    "        token_positions[keys[i]] = position\n",
    "    return token_positions\n",
    "\n",
    "\n",
    "def get_tokens_with_positions(row):\n",
    "    '''\n",
    "    Returns \n",
    "    final_tokens : Text onverted to tokens\n",
    "    token_positions : dictionary containing token position for a,b and p\n",
    "    \n",
    "    Example:\n",
    "    index = 5\n",
    "    print(train_df.iloc[index])\n",
    "    final_tokens, token_positions = get_tokens_with_positions(train_df.iloc[index])\n",
    "    print(final_tokens, token_positions)\n",
    "    [final_tokens[v] for v in token_positions.values()]\n",
    "    '''\n",
    "    tokens_arr, keys = get_tokens_array(row)\n",
    "    \n",
    "    final_tokens = []\n",
    "    for tokens in tokens_arr:\n",
    "        final_tokens = final_tokens + tokens \n",
    "    \n",
    "    token_positions = get_token_pos(tokens_arr, keys)\n",
    "    return final_tokens, token_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                                    development-6\n",
      "Text              Sandra Collins is an American DJ. She got her ...\n",
      "Pronoun                                                         She\n",
      "Pronoun-offset                                                  411\n",
      "A                                                           Collins\n",
      "A-offset                                                        236\n",
      "A-coref                                                        True\n",
      "B                                                                DJ\n",
      "B-offset                                                        347\n",
      "B-coref                                                       False\n",
      "URL                     http://en.wikipedia.org/wiki/Sandra_Collins\n",
      "Name: 5, dtype: object\n",
      "['sandra', 'collins', 'is', 'an', 'american', 'dj', '.', 'she', 'got', 'her', 'start', 'on', 'the', 'west', 'coast', 'of', 'the', 'u', '.', 's', '.', 'in', 'phoenix', ',', 'arizona', 'and', 'into', 'reside', '##ncies', 'in', 'los', 'angeles', ',', 'and', 'eventually', 'moved', 'towards', 'trance', '.', 'she', 'used', 'american', 'producers', 'to', 'give', 'herself', 'a', 'unique', 'sound', '.', 'collins', 'performed', 'for', 'an', 'estimated', '80', ',', '000', 'people', 'on', 'the', 'first', 'night', 'of', 'woodstock', \"'\", '99', ',', 'and', 'was', 'the', 'first', 'female', 'dj', 'featured', 'in', 'the', 'trance', '##port', 'series', 'of', 'influential', 'recordings', '.', 'she', 'recently', 'has', 'released', 'two', 'cd', 'mixes', 'under', 'paul', 'oak', '##en', '##fold', \"'\", 's', 'perfect', '##o', 'label', '.'] {'a': 50, 'b': 73, 'p': 84}\n",
      "['collins', 'dj', 'she']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[84, 50, 73]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 5\n",
    "row = train_df.iloc[index]\n",
    "print(row)\n",
    "final_tokens, token_positions = get_tokens_with_positions(row)\n",
    "print(final_tokens, token_positions)\n",
    "\n",
    "\n",
    "assert(row['Pronoun'].lower() == final_tokens[token_positions['p']])\n",
    "\n",
    "print([final_tokens[v] for v in token_positions.values()])\n",
    "[token_positions[key] for key in 'pab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_df.iloc[0]['A-coref']:\n",
    "    print ('yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Format:\n",
    "    \n",
    "text_tokens\tPindex,Aindex,Bindex\tlabel(0,1,2)\n",
    "\n",
    "labels:\n",
    "0= Neither\n",
    "1 = A\n",
    "2 = B\n",
    "\n",
    "Without knowing P\n",
    "\n",
    "Softmax over [CLS],A,B index, loss with labels\n",
    "\n",
    "With knowing P\n",
    "Softmax over [CLS] * P ,A * P ,B * P index, loss with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_features(df):\n",
    "    processed_df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        #print(i)\n",
    "        row = df.iloc[i]\n",
    "        final_tokens, token_positions = get_tokens_with_positions(row)\n",
    "        \n",
    "        \n",
    "        assert(final_tokens[token_positions['p']] in row['Pronoun'].lower())\n",
    "        assert(final_tokens[token_positions['a']] in row['A'].lower()), print(row)\n",
    "        assert(final_tokens[token_positions['b']] in row['B'].lower())\n",
    "        \n",
    "        ids = tokenizer.convert_tokens_to_ids(final_tokens)\n",
    "        pab_position = [token_positions[key] for key in 'pab']\n",
    "        label = 1 if row['A-coref'] else ( 2 if row['B-coref'] else 0)\n",
    "        \n",
    "        processed_df = processed_df.append({'input':np.array(ids), 'pab_pos':np.array(pab_position), 'label':label}, ignore_index=True)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  label        pab_pos\n",
      "0  [11199, 10093, 3877, 1011, 1011, 2209, 1996, 2...    1.0   [61, 41, 44]\n",
      "1  [2002, 3473, 2039, 1999, 6473, 2669, 1010, 430...    1.0   [60, 50, 53]\n",
      "2  [2002, 2018, 2042, 20847, 2000, 3519, 1010, 20...    2.0   [62, 40, 56]\n",
      "3  [1996, 2783, 2372, 1997, 4126, 2031, 2036, 286...    2.0   [66, 35, 70]\n",
      "4  [2014, 4203, 10768, 3850, 2834, 1999, 2384, 20...    2.0  [104, 53, 71]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "      <th>pab_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[11199, 10093, 3877, 1011, 1011, 2209, 1996, 2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[61, 41, 44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2002, 3473, 2039, 1999, 6473, 2669, 1010, 430...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[60, 50, 53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2002, 2018, 2042, 20847, 2000, 3519, 1010, 20...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[62, 40, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1996, 2783, 2372, 1997, 4126, 2031, 2036, 286...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[66, 35, 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2014, 4203, 10768, 3850, 2834, 1999, 2384, 20...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[104, 53, 71]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  label        pab_pos\n",
       "0  [11199, 10093, 3877, 1011, 1011, 2209, 1996, 2...    1.0   [61, 41, 44]\n",
       "1  [2002, 3473, 2039, 1999, 6473, 2669, 1010, 430...    1.0   [60, 50, 53]\n",
       "2  [2002, 2018, 2042, 20847, 2000, 3519, 1010, 20...    2.0   [62, 40, 56]\n",
       "3  [1996, 2783, 2372, 1997, 4126, 2031, 2036, 286...    2.0   [66, 35, 70]\n",
       "4  [2014, 4203, 10768, 3850, 2834, 1999, 2384, 20...    2.0  [104, 53, 71]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = create_features(val_df)\n",
    "print(processed_df.head())\n",
    "\n",
    "#for reading purpose\n",
    "processed_df.to_csv('val_processed.tsv', sep='\\t')\n",
    "\n",
    "#saving to TSV will not store the data types of ndarray. It converts them to str\n",
    "processed_df.to_pickle('val_processed.pkl')\n",
    "df = pd.read_pickle('val_processed.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  label        pab_pos\n",
      "0  [11199, 10093, 3877, 1011, 1011, 2209, 1996, 2...    1.0   [61, 41, 44]\n",
      "1  [2002, 3473, 2039, 1999, 6473, 2669, 1010, 430...    1.0   [60, 50, 53]\n",
      "2  [2002, 2018, 2042, 20847, 2000, 3519, 1010, 20...    2.0   [62, 40, 56]\n",
      "3  [1996, 2783, 2372, 1997, 4126, 2031, 2036, 286...    2.0   [66, 35, 70]\n",
      "4  [2014, 4203, 10768, 3850, 2834, 1999, 2384, 20...    2.0  [104, 53, 71]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "      <th>pab_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[11199, 10093, 3877, 1011, 1011, 2209, 1996, 2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[61, 41, 44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2002, 3473, 2039, 1999, 6473, 2669, 1010, 430...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[60, 50, 53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2002, 2018, 2042, 20847, 2000, 3519, 1010, 20...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[62, 40, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1996, 2783, 2372, 1997, 4126, 2031, 2036, 286...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[66, 35, 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2014, 4203, 10768, 3850, 2834, 1999, 2384, 20...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[104, 53, 71]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  label        pab_pos\n",
       "0  [11199, 10093, 3877, 1011, 1011, 2209, 1996, 2...    1.0   [61, 41, 44]\n",
       "1  [2002, 3473, 2039, 1999, 6473, 2669, 1010, 430...    1.0   [60, 50, 53]\n",
       "2  [2002, 2018, 2042, 20847, 2000, 3519, 1010, 20...    2.0   [62, 40, 56]\n",
       "3  [1996, 2783, 2372, 1997, 4126, 2031, 2036, 286...    2.0   [66, 35, 70]\n",
       "4  [2014, 4203, 10768, 3850, 2834, 1999, 2384, 20...    2.0  [104, 53, 71]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = create_features(train_df)\n",
    "print(processed_df.head())\n",
    "\n",
    "processed_df.to_csv('train_processed.tsv', sep='\\t')\n",
    "\n",
    "processed_df.to_pickle('train_processed.pkl')\n",
    "df = pd.read_pickle('train_processed.pkl')\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
